2025-05-20 11:58:58,418 - asyncio - DEBUG - Using selector: EpollSelector
2025-05-20 11:58:58,421 - __main__ - INFO - Processing file: sample_document.txt
2025-05-20 11:58:58,421 - __main__ - INFO - Created 20 chunks
2025-05-20 11:58:58,422 - __main__ - INFO - Running pipeline on 20 chunks for 2 rounds
2025-05-20 11:58:58,455 - __main__ - INFO - Planning conversation scenarios
2025-05-20 11:58:58,877 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'User-Agent': 'pydantic-ai/0.2.4'}, 'files': None, 'idempotency_key': 'stainless-python-retry-6abc5b4b-9b58-4af1-9d27-0e2e64ded384', 'json_data': {'messages': [{'role': 'system', 'content': '\nYou are an expert at analyzing document content to identify potential conversation scenarios.\nYour task is to:\n1) Identify the primary domain of the documents.\n2) Extract key topics covered.\n3) Generate user personas.\n4) Create realistic scenarios for each persona.\nReturn a JSON strictly matching the ScenarioResult schema.\n        '}, {'role': 'user', 'content': 'Analyze documents and identify potential conversation scenarios'}], 'model': 'meta-llama/Llama-3.3-70B-Instruct-Turbo', 'n': 1, 'stream': False, 'tool_choice': 'required', 'tools': [{'type': 'function', 'function': {'name': 'extract_domain_topics', 'description': '<summary>Extract the primary domain and key topics from document chunks using an LLM.</summary>\n<returns>\n<description>Dictionary with domain and topics information.</description>\n</returns>', 'parameters': {'additionalProperties': False, 'properties': {}, 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'generate_user_personas', 'description': '<summary>Generate potential user personas using an LLM based on document content, domain, and topics.</summary>\n<returns>\n<description>List of user persona dictionaries.</description>\n</returns>', 'parameters': {'additionalProperties': False, 'properties': {'domain': {'description': 'The identified domain.', 'type': 'string'}, 'topics': {'description': 'List of key topics.', 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['domain', 'topics'], 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'generate_initial_questions', 'description': '<summary>Generate initial questions and scenario details for each persona using an LLM.</summary>\n<returns>\n<description>List of scenario dictionaries.</description>\n</returns>', 'parameters': {'additionalProperties': False, 'properties': {'domain': {'description': 'The identified domain.', 'type': 'string'}, 'topics': {'description': 'List of key topics.', 'items': {'type': 'string'}, 'type': 'array'}, 'personas': {'description': 'List of user persona dictionaries.', 'items': {'additionalProperties': True, 'type': 'object'}, 'type': 'array'}}, 'required': ['domain', 'topics', 'personas'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'final_result', 'description': 'The final response which ends this conversation', 'parameters': {'properties': {'domain': {'description': 'Primary domain', 'type': 'string'}, 'topics': {'description': 'Key topics', 'items': {'type': 'string'}, 'type': 'array'}, 'scenarios': {'description': 'Generated scenarios', 'items': {'$ref': '#/$defs/Scenario'}, 'type': 'array'}}, 'required': ['domain', 'topics', 'scenarios'], 'type': 'object', '$defs': {'Scenario': {'properties': {'scenario_id': {'description': 'Unique ID', 'type': 'integer'}, 'title': {'description': 'Scenario title', 'type': 'string'}, 'persona': {'description': 'User persona', 'anyOf': [{'$ref': '#/$defs/UserPersona'}]}, 'context': {'description': 'Situation context', 'type': 'string'}, 'initial_question': {'description': 'First user question', 'type': 'string'}, 'information_needs': {'description': 'Info needs list', 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['scenario_id', 'title', 'persona', 'context', 'initial_question', 'information_needs'], 'type': 'object'}, 'UserPersona': {'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'Persona name'}, 'type': {'description': 'Persona role/type', 'type': 'string'}, 'background': {'description': 'Persona background', 'type': 'string'}, 'goals': {'description': 'Persona goals', 'type': 'string'}}, 'required': ['type', 'background', 'goals'], 'type': 'object'}}}}}]}}
2025-05-20 11:58:58,879 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.deepinfra.com/v1/openai/chat/completions
2025-05-20 11:58:58,889 - httpcore.connection - DEBUG - connect_tcp.started host='api.deepinfra.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-05-20 11:58:59,309 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x7f7280db1340>
2025-05-20 11:58:59,309 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7281bc38d0> server_hostname='api.deepinfra.com' timeout=5.0
2025-05-20 11:58:59,612 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x7f72817e3020>
2025-05-20 11:58:59,613 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-20 11:58:59,614 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-20 11:58:59,614 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-20 11:58:59,614 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-20 11:58:59,614 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-20 11:59:00,223 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 20 May 2025 06:29:00 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'499'), (b'Connection', b'keep-alive'), (b'server', b'uvicorn'), (b'x-robots-tag', b'noindex')])
2025-05-20 11:59:00,225 - httpx - INFO - HTTP Request: POST https://api.deepinfra.com/v1/openai/chat/completions "HTTP/1.1 200 OK"
2025-05-20 11:59:00,226 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-20 11:59:00,226 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-20 11:59:00,226 - httpcore.http11 - DEBUG - response_closed.started
2025-05-20 11:59:00,227 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-20 11:59:00,227 - openai._base_client - DEBUG - HTTP Response: POST https://api.deepinfra.com/v1/openai/chat/completions "200 OK" Headers({'date': 'Tue, 20 May 2025 06:29:00 GMT', 'content-type': 'application/json', 'content-length': '499', 'connection': 'keep-alive', 'server': 'uvicorn', 'x-robots-tag': 'noindex'})
2025-05-20 11:59:00,227 - openai._base_client - DEBUG - request_id: None
2025-05-20 11:59:00,235 - __main__ - ERROR - Pipeline error: Expected code to be unreachable, but got: UserPromptPart(content='\nBased on the document below, identify:\n1) The primary domain.\n2) Up to 5...
Traceback (most recent call last):
  File "/home/saranathp/agentic-conversation-generator/main.py", line 83, in run_conversation_pipeline
    scenario_run = await scenario_planning_agent.run(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/agent.py", line 459, in run
    async for _ in agent_run:
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/agent.py", line 1931, in __anext__
    next_node = await self._graph_run.__anext__()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_graph/graph.py", line 810, in __anext__
    return await self.next(self._next_node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_graph/graph.py", line 783, in next
    self._next_node = await node.run(ctx)
                      ^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/_agent_graph.py", line 380, in run
    async with self.stream(ctx):
               ^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.12/contextlib.py", line 217, in __aexit__
    await anext(self.gen)
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/_agent_graph.py", line 394, in stream
    async for _event in stream:
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/_agent_graph.py", line 443, in _run_stream
    async for event in self._events_iterator:
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/_agent_graph.py", line 421, in _run_stream
    async for event in self._handle_tool_calls(ctx, tool_calls):
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/_agent_graph.py", line 472, in _handle_tool_calls
    async for event in process_function_tools(
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/_agent_graph.py", line 663, in process_function_tools
    result = task.result()
             ^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/tools.py", line 329, in run
    return await self._run(message, run_context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/tools.py", line 346, in _run
    response_content = await function(*args, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/agents/scenario_planning.py", line 130, in extract_domain_topics
    sub_result = await sub_agent.run(message_history=messages)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/agent.py", line 459, in run
    async for _ in agent_run:
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/agent.py", line 1931, in __anext__
    next_node = await self._graph_run.__anext__()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_graph/graph.py", line 810, in __anext__
    return await self.next(self._next_node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_graph/graph.py", line 783, in next
    self._next_node = await node.run(ctx)
                      ^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/_agent_graph.py", line 270, in run
    return await self._make_request(ctx)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/_agent_graph.py", line 323, in _make_request
    model_response = await ctx.deps.model.request(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/models/openai.py", line 197, in request
    response = await self._completions_create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/models/openai.py", line 266, in _completions_create
    openai_messages = await self._map_messages(messages)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saranathp/agentic-conversation-generator/.venv/lib64/python3.12/site-packages/pydantic_ai/models/openai.py", line 356, in _map_messages
    assert_never(message)
  File "/usr/lib64/python3.12/typing.py", line 2443, in assert_never
    raise AssertionError(f"Expected code to be unreachable, but got: {value}")
AssertionError: Expected code to be unreachable, but got: UserPromptPart(content='\nBased on the document below, identify:\n1) The primary domain.\n2) Up to 5...
2025-05-20 11:59:00,245 - __main__ - INFO - Full results: results/conversation_results_20250520_115858.json
2025-05-20 11:59:00,245 - __main__ - INFO - Simplified: results/simplified_20250520_115858.json
2025-05-20 11:59:00,245 - __main__ - INFO - Total tokens used: 1154
2025-05-20 11:59:00,245 - __main__ - INFO - request_tokens: 1145
2025-05-20 11:59:00,245 - __main__ - INFO - requests: 1
2025-05-20 11:59:00,245 - __main__ - INFO - response_tokens: 9
